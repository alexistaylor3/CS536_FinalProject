{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexistaylor3/CS536_FinalProject/blob/main/CS536FinalProjectDefaultCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7vrWkUzsg1m"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WTiNGOGA-w6"
      },
      "outputs": [],
      "source": [
        "#make sure we are running off of the GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\");\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LW07RE1v2bG9"
      },
      "outputs": [],
      "source": [
        "# Settings to use for both model\n",
        "beta_1 = 0.0\n",
        "betas = [0.8, 0.9, 0.95, 0.99]\n",
        "batchsize = 8\n",
        "batchSizes = [8, 16, 32]\n",
        "epochs = 100\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BehG0yWp0Eus"
      },
      "outputs": [],
      "source": [
        "# Main code\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "\n",
        "# functions to show an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "def show_some_pictures(j ):\n",
        "    # get some random training images\n",
        "    dataiter = iter(trainloader)\n",
        "    images, labels = dataiter.next()\n",
        "\n",
        "    # show images\n",
        "    imshow(torchvision.utils.make_grid(images))\n",
        "    # print labels\n",
        "    print(' '.join('%5s' % classes[labels[j]] for j in range(j)))\n",
        "\n",
        "\n",
        "def random_test():\n",
        "    dataiter = iter(testloader)\n",
        "    images, labels = dataiter.next()\n",
        "\n",
        "    # print images\n",
        "    imshow(torchvision.utils.make_grid(images))\n",
        "    print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "    net = Net()\n",
        "    net.load_state_dict(torch.load(PATH))\n",
        "    outputs = net(images)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                                  for j in range(4)))\n",
        "\n",
        "def train(net, noe, filepath_trainloss, filepath_testacc, filepath_trainacc, initial_lr,  batchsize, device):\n",
        "    doc = open(filepath_trainloss+'.txt', \"w\")\n",
        "    doc2 = open(filepath_testacc+'.txt', \"w\")\n",
        "    doc3 = open(filepath_trainacc+'.txt', \"w\")\n",
        "    check_interval=1000\n",
        "    batch_number = int(6000*8/(batchsize*check_interval))\n",
        "    # print(batch_number)\n",
        "    training_loss_vec = [] #np.zeros(noe*check_interval)\n",
        "    train_acc_vec = [] #np.zeros(noe*check_interval)\n",
        "    test_acc_vec = [] #np.zeros(noe*check_interval)\n",
        "    for epoch in range(noe):  # loop over the dataset multiple times\n",
        "        time_begin  = time.time()\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data[0].to(device, non_blocking=True), data[1].to(device, non_blocking=True)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            if i % check_interval == (check_interval-1):    # print every 2000 mini-batches\n",
        "                time_end = time.time()\n",
        "                time_elapsed = time_end - time_begin\n",
        "                time_begin = time.time()\n",
        "                print('[%d, %5d] loss: %.3f, Time Taken %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / check_interval, time_elapsed))\n",
        "                running_loss = 0.0\n",
        "        if epoch % 20 == 0:\n",
        "            time_end = time.time()\n",
        "            time_elapsed = time_end - time_begin\n",
        "            time_begin = time.time()\n",
        "            print(\"\\tTesting Time: \", time_elapsed)\n",
        "            training_loss_vec.append(running_loss/check_interval)\n",
        "            train_acc = train_accuracy(net)\n",
        "            train_acc_vec.append(train_acc)\n",
        "            test_acc = test_accuracy(net)\n",
        "            test_acc_vec.append(test_acc)\n",
        "            print(running_loss / check_interval, file=doc)\n",
        "            print(test_acc, file=doc2)\n",
        "            print(train_acc, file=doc3)\n",
        "        if epoch % 1 == 0:\n",
        "            for p in optimizer.param_groups:\n",
        "                p['lr'] = initial_lr/np.sqrt(1+epoch)\n",
        "    training_loss_vec.append(running_loss/check_interval)\n",
        "    train_acc = train_accuracy(net)\n",
        "    train_acc_vec.append(train_acc)\n",
        "    test_acc = test_accuracy(net)\n",
        "    test_acc_vec.append(test_acc)\n",
        "    print(running_loss / check_interval, file=doc)\n",
        "    print(test_acc, file=doc2)\n",
        "    print(train_acc, file=doc3)\n",
        "    doc.close()\n",
        "    doc2.close()\n",
        "\n",
        "    xvar = np.arange(len(training_loss_vec)) * 20\n",
        "    plt.figure(1)\n",
        "    plt.title(\"Training Loss\", fontsize=15)\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('training loss')\n",
        "    plt.plot(xvar, np.array(training_loss_vec))\n",
        "    plt.savefig(filepath_trainloss+'.png')\n",
        "\n",
        "    plt.figure(2)\n",
        "    plt.title(\"Test Accuracy\", fontsize=15)\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('test accuracy(%)')\n",
        "    plt.plot(xvar, np.array(test_acc_vec), label=\"Test accuracy\")\n",
        "    plt.legend()\n",
        "    plt.savefig(filepath_testacc + '.png')\n",
        "\n",
        "    plt.figure(2)\n",
        "    plt.title(\"Training and Test Accuracy\", fontsize=15)\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('training accuracy(%)')\n",
        "    plt.plot(xvar, np.array(train_acc_vec), label=\"Training accuracy\")\n",
        "    plt.legend()\n",
        "    plt.savefig(filepath_trainacc + '.png')\n",
        "\n",
        "def train_accuracy(net):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in trainloader:\n",
        "            images, labels = data[0].to(device, non_blocking=True), data[1].to(device, non_blocking=True)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "def test_accuracy(net):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[0].to(device, non_blocking=True), data[1].to(device, non_blocking=True)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Nhc4CWDaudNI"
      },
      "outputs": [],
      "source": [
        "# data sets\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "# resnet\n",
        "net = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=False)\n",
        "net = net.to(device)\n",
        "net.eval()\n",
        "# # cifar_resnet.py\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "PATH = './cifar_net_Adam.pth'\n",
        "for beta in betas:\n",
        "    beta_2 = beta\n",
        "    for batchSize in batchSizes:\n",
        "        batchsize = batchSize\n",
        "        net = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=False)\n",
        "        net = net.to(device)\n",
        "        optimizer = optim.Adam(net.parameters(), lr=0.001, betas=(beta_1, beta), eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "\n",
        "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchsize,\n",
        "                                          shuffle=True, num_workers=8,  pin_memory=True)\n",
        "\n",
        "        testloader = torch.utils.data.DataLoader(testset, batch_size=batchsize,\n",
        "                                         shuffle=False, num_workers=8,  pin_memory=True)\n",
        "        train(net, epochs, \"Exp1-training-loss-beta1=\"+str(beta_1)+\";beta2=\"+str(beta)+\";bs=\"+str(batchSize), \"Exp1-test-accuracy-beta1=\"+str(beta_1)+\";beta2=\"+str(beta_2)+\";bs=\"+str(batchsize), \"Exp1-train-accuracy-beta1=\"+str(beta_1)+\";beta2=\"+str(beta_2)+\";bs=\"+str(batchsize), 0.001, batchsize, device)\n",
        "        torch.save(net.state_dict(), PATH)\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZHDhvPxEumi-"
      },
      "outputs": [],
      "source": [
        "# cifar_resnet_SGD.py\n",
        "net = net.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=beta_1, dampening=0, weight_decay=0, nesterov=False)\n",
        "PATH = './cifar_net_SGD.pth'\n",
        "for batchSize in batchSizes:\n",
        "    train(net, epochs, \"Exp1-training-loss-beta1=\"+str(beta_1)+\";bs=\"+str(batchSize), \"Exp1-test-accuracy-beta1=\"+str(beta_1)+\";bs=\"+str(batchSize), \"Exp1-train-accuracy-beta1=\"+str(beta_1)+\";bs=\"+str(batchSize), 0.001, batchSize, device)\n",
        "    torch.save(net.state_dict(), PATH)\n",
        "print('Finished Training')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}