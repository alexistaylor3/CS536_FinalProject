{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7vrWkUzsg1m"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WTiNGOGA-w6",
        "outputId": "410ce9ac-ac43-4365-d209-6628344b9648"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "#make sure we are running off of the GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\");\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LW07RE1v2bG9"
      },
      "outputs": [],
      "source": [
        "# Settings to use for both model\n",
        "beta_1 = 0.0\n",
        "betas = [0.8, 0.9, 0.95, 0.99]\n",
        "batchsize = 8\n",
        "batchSizes = [8, 16, 32]\n",
        "epochs = 2\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BehG0yWp0Eus",
        "outputId": "10819aab-1c35-40c2-9471-b9f2a52fd52a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:05<00:00, 29.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Main code\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "\n",
        "# functions to show an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "def show_some_pictures(j ):\n",
        "    # get some random training images\n",
        "    dataiter = iter(trainloader)\n",
        "    images, labels = dataiter.next()\n",
        "\n",
        "    # show images\n",
        "    imshow(torchvision.utils.make_grid(images))\n",
        "    # print labels\n",
        "    print(' '.join('%5s' % classes[labels[j]] for j in range(j)))\n",
        "\n",
        "\n",
        "def random_test():\n",
        "    dataiter = iter(testloader)\n",
        "    images, labels = dataiter.next()\n",
        "\n",
        "    # print images\n",
        "    imshow(torchvision.utils.make_grid(images))\n",
        "    print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "    net = Net()\n",
        "    net.load_state_dict(torch.load(PATH))\n",
        "    outputs = net(images)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                                  for j in range(4)))\n",
        "\n",
        "def train(net, noe, filepath_trainloss, filepath_testacc, filepath_trainacc, initial_lr,  batchsize, device):\n",
        "    doc = open(filepath_trainloss+'.txt', \"w\")\n",
        "    doc2 = open(filepath_testacc+'.txt', \"w\")\n",
        "    doc3 = open(filepath_trainacc+'.txt', \"w\")\n",
        "    check_interval=1000\n",
        "    batch_number = int(6000*8/(batchsize*check_interval))\n",
        "    # print(batch_number)\n",
        "    training_loss_vec = [] #np.zeros(noe*check_interval)\n",
        "    train_acc_vec = [] #np.zeros(noe*check_interval)\n",
        "    test_acc_vec = [] #np.zeros(noe*check_interval)\n",
        "    for epoch in range(noe):  # loop over the dataset multiple times\n",
        "        time_begin  = time.time()\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data[0].to(device, non_blocking=True), data[1].to(device, non_blocking=True)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            if i % check_interval == (check_interval-1):    # print every 2000 mini-batches\n",
        "                time_end = time.time()\n",
        "                time_elapsed = time_end - time_begin\n",
        "                time_begin = time.time()\n",
        "                print('[%d, %5d] loss: %.3f, Time Taken %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / check_interval, time_elapsed))\n",
        "                running_loss = 0.0\n",
        "        if epoch % 20 == 0:\n",
        "            time_end = time.time()\n",
        "            time_elapsed = time_end - time_begin\n",
        "            time_begin = time.time()\n",
        "            print(\"\\tTesting Time: \", time_elapsed)\n",
        "            training_loss_vec.append(running_loss/check_interval)\n",
        "            train_acc = train_accuracy(net)\n",
        "            train_acc_vec.append(train_acc)\n",
        "            test_acc = test_accuracy(net)\n",
        "            test_acc_vec.append(test_acc)\n",
        "            print(running_loss / check_interval, file=doc)\n",
        "            print(test_acc, file=doc2)\n",
        "            print(train_acc, file=doc3)\n",
        "        if epoch % 1 == 0:\n",
        "            for p in optimizer.param_groups:\n",
        "                p['lr'] = initial_lr/np.sqrt(1+epoch)\n",
        "    #alex change 1\n",
        "    # training_loss_vec.append(running_loss/check_interval)\n",
        "    # train_acc = train_accuracy(net)\n",
        "    # train_acc_vec.append(train_acc)\n",
        "    # test_acc = test_accuracy(net)\n",
        "    # test_acc_vec.append(test_acc)\n",
        "    # print(running_loss / check_interval, file=doc)\n",
        "    # print(test_acc, file=doc2)\n",
        "    # print(train_acc, file=doc3)\n",
        "    doc.close()\n",
        "    doc2.close()\n",
        "\n",
        "    xvar = np.arange(len(training_loss_vec)) * 20\n",
        "    plt.figure(1)\n",
        "    plt.title(\"Training Loss\", fontsize=15)\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('training loss')\n",
        "    plt.plot(xvar, np.array(training_loss_vec))\n",
        "    plt.savefig(filepath_trainloss+'.png')\n",
        "\n",
        "    plt.figure(2)\n",
        "    plt.title(\"Test Accuracy\", fontsize=15)\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('test accuracy(%)')\n",
        "    plt.plot(xvar, np.array(test_acc_vec), label=\"Test accuracy\")\n",
        "    plt.legend()\n",
        "    plt.savefig(filepath_testacc + '.png')\n",
        "\n",
        "    plt.figure(2)\n",
        "    plt.title(\"Training and Test Accuracy\", fontsize=15)\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('training accuracy(%)')\n",
        "    plt.plot(xvar, np.array(train_acc_vec), label=\"Training accuracy\")\n",
        "    plt.legend()\n",
        "    plt.savefig(filepath_trainacc + '.png')\n",
        "\n",
        "def train_accuracy(net):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in trainloader:\n",
        "            images, labels = data[0].to(device, non_blocking=True), data[1].to(device, non_blocking=True)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "def test_accuracy(net):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[0].to(device, non_blocking=True), data[1].to(device, non_blocking=True)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# data sets\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchsize,\n",
        "                                          shuffle=True, num_workers=8,  pin_memory=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batchsize,\n",
        "                                         shuffle=False, num_workers=8,  pin_memory=True)\n",
        "# resnet\n",
        "net = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=False)\n",
        "net.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nhc4CWDaudNI",
        "outputId": "6faf89f1-7431-494c-8ce3-e1be35622aec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/zipball/v0.6.0\" to /root/.cache/torch/hub/v0.6.0.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,  1000] loss: 2.195, Time Taken 262.106\n",
            "[1,  2000] loss: 1.879, Time Taken 263.773\n",
            "[1,  3000] loss: 1.787, Time Taken 264.328\n",
            "[1,  4000] loss: 1.708, Time Taken 264.758\n",
            "[1,  5000] loss: 1.646, Time Taken 276.819\n",
            "[1,  6000] loss: 1.601, Time Taken 283.213\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "x and y must have same first dimension, but have shapes (6,) and (1,)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3082971633.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         testloader = torch.utils.data.DataLoader(testset, batch_size=batchsize,\n\u001b[1;32m     17\u001b[0m                                          shuffle=False, num_workers=0)\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Exp1-training-loss-beta1=\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\";beta2=\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\";bs=\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Exp1-test-accuracy-beta1=\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\";beta2=\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\";bs=\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Exp1-train-accuracy-beta1=\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\";beta2=\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\";bs=\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finished Training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3515131515.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, noe, filepath_trainloss, filepath_testacc, filepath_trainacc, initial_lr, batchsize, device)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loss_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_trainloss\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3827\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3828\u001b[0m ) -> list[Line2D]:\n\u001b[0;32m-> 3829\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   3830\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3831\u001b[0m         \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \"\"\"\n\u001b[1;32m   1776\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1777\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1778\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    298\u001b[0m                 \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    495\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (6,) and (1,)"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAHJCAYAAABpOFaGAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAMe5JREFUeJzt3Xt0TXf+//HXSciJfElQJKGHuNStiNY1Lj90QubLoqYdcWkFdZm2eiGlqBLKCP2WqtIxVWo605ZW0SoTo9EomtY1Ha270KQdCYrErQnJ/v3R5cycEZpDTk6Sz/Ox1llLPvuz937vfHBea+/P3ttmWZYlAAAAA/l4uwAAAABvIQgBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAFlgM1mc+sTFhZW5DWEhYXJZrOVuG0Vteu/QwBlQzlvFwDgzg0ZMuSGtm3btunYsWMKDw9Xy5YtXZZVq1atmCoDgJKNIASUAcuXL7+hbejQoTp27Jj69u2radOmebyGxMREXb16tcRtCwBuhSAEoEjUr1+/RG4LAG6FOUKAYZYvXy6bzaZp06bp8OHDGjBggIKDg+Xj46O1a9dKko4ePapp06YpIiJCISEh8vPz0913362YmBgdPny4wO0WNK/nxIkTstls6tq1q65cuaKJEyeqTp06stvtatCggebMmSPLsjy6LUnasmWLHnjgAVWqVElVqlRRz549tWvXLpffhaekp6frD3/4g7PWGjVq6KGHHtLOnTsL7P/tt9/q0UcfVb169eTv76/q1aurZcuWGjNmjE6ePOnS98svv1Tfvn2d2w4JCVHbtm01ceJEXbx40WPHBJQlnBECDHXo0CG1adNGd911l7p166Zz586pfPnykqS33npLL7/8spo1a6Y2bdrIbrdr//79+utf/6qPP/5YW7duVYsWLQq9r9zcXPXo0UP79+9X165ddenSJW3ZskUTJ07UhQsXNHPmTI9ta/Xq1YqOjlZeXp7at2+vsLAw7du3T506ddKwYcMKvd/bsW/fPj3wwAM6c+aMGjVqpIceekhpaWlas2aN1q1bp/fee0/9+vVz9t+9e7c6deqkn3/+WS1atNCDDz6oy5cvKzU1Va+99pr69u2r0NBQSdK6devUt29fWZaltm3bqkOHDjp//ryOHDmiOXPm6PHHH1fFihU9enxAmWABKJOGDBliSbLi4uJc2t9++21LkiXJeuqpp6xr167dsG5ycrKVmpp6Q/uyZcssSVa3bt1uWFanTh3rv/9LOX78uHNfXbp0sbKyspzLdu7cafn6+loBAQHWhQsXPLKtrKwsq2rVqpYk691333XZ3pQpU5zb++/f0a1cX+fX5OfnW82bN7ckWc8//7yVn5/vXLZq1SrLx8fHqlixovWvf/3L2R4TE2NJsl555ZUbtnfgwAGXvv/v//0/S5K1atWqG/ru2LHDys7OLvQxASbj0hhgqOrVq2vOnDny9fW9YVn79u1Vt27dG9qHDRumjh07KikpSVlZWYXel4+Pj/785z8rMDDQ2da6dWv97//+ry5fvqxdu3Z5ZFsffPCBzp49q9/85jcaNGiQy3amTp2qOnXqFHq/7kpKStK+fftUu3ZtzZw50+VS38MPP6y+ffvq4sWLWrZsmbP99OnTkqTIyMgbtte4cWPn2aBf69umTRtVqlSpyI4FKMsIQoChIiMjFRAQcNPlFy9e1Pvvv68JEyZo5MiRGjp0qIYOHaqTJ0/KsiwdO3as0PuqU6eOGjVqdEN7w4YNJemGuS9Fta3t27dLksvlp+vKlSunhx9+uND7ddfWrVslSdHR0c5Ljv9p8ODBLv0kqVWrVpKk0aNHKykpSdeuXbvp9q/3HTx4sHbu3Kn8/Pwiqx0wCXOEAEPVrl37pss2b96sAQMGOM86FOTChQuF3tfdd99dYPv1sxY5OTke2db1UORwOApc51a/gzv1r3/9S5Ju+vDK6+0//vijs238+PHatm2bkpKS1K1bN1WsWFERERHq1auXhg4dqqCgIGffWbNmad++fVq3bp3WrVunKlWqqFOnTurTp48effRR+fv7e+zYgLKEM0KAoW72RXnx4kVFR0frzJkzmjp1qvbv369Lly4pPz9flmVp4MCBknTTO7QK4uNTdP/VFOW2vKmgp1MHBgZq8+bN2rp1q55//nk1bdpUmzdv1pgxY9SoUSMdOXLE2dfhcGjXrl3auHGjnn76aTkcDq1bt04jR45UixYt9NNPPxXn4QClVtn4HwVAkdm6dat++uknPfzww5o+fbqaNGmigIAA5xd3amqqlyssvOtzatLT0wtcfrP2olCzZk1J0vfff1/g8hMnTkiSatWq5dJus9nUqVMnzZkzR19//bX+9a9/aeDAgcrMzNTkyZNd+pYrV049evTQggUL9M033+jEiRN64IEHnHeOAfh1BCEALs6dOyep4EtQR48e1Z49e4q7pNvWsWNHSdJHH310w7K8vDytXr3aY/vu3LmzJOnDDz9UXl7eDcv/9re/ufS7mRo1ajifc/Ttt9/esm+dOnU0YcKEQvUF8AuCEAAX1ycdr1692mWO0Pnz5zV8+PBS9eqLfv36qWrVqtq0aZNWrFjhsmzmzJk6fvy4x/bdtWtXNW/eXCdOnNDUqVNdLiWuWbNGq1evVsWKFfXYY4852xcvXlxgTRs2bJDkOtfp1VdfVUZGRqH6Arg5JksDcNG6dWt1795dmzZtUsOGDdW1a1dJv9wOXq1aNT344IP6+OOPvVtkIQUFBWnJkiWKjo7WwIEDtWDBAucDFQ8fPqxRo0bpzTfflJ+fn9vbbt++/U2XjRgxQiNGjNC7776rbt26adasWVqzZo1atmyptLQ0bd++XeXKldPSpUtdbolfvHixnnjiCTVt2lRNmjRRuXLldPDgQX3zzTfy9/fX1KlTnX2nT5+ucePGKTw8XPfcc48sy9I333yjw4cPq2rVqho3bpzbxwSYiDNCAG7w8ccfa/Lkyapevbr+/ve/a/fu3RowYIC++uorVa5c2dvlueWhhx7SZ599pq5du+qf//yn1q9fr5o1a2rr1q3Ou8buuusut7f79ddf3/Tzww8/SJKaN2+uPXv2aOTIkbp48aJWrVqlQ4cOqW/fvtq+fbuio6Ndtjljxgw99thjstlsSkxM1Lp163TlyhWNGDFCKSkpzkt9kvT6669rwIABunz5sv7+978rISFB5cqVU2xsrP75z3/qnnvuuYPfGmAOm+XOrR8AUIb89re/1caNG/XVV1+pXbt23i4HgBdwRghAmfbjjz8qMzPTpS0/P1+vvvqqNm7cqIYNG6pt27Zeqg6AtzFHCECZtnXrVj366KO67777VKdOHeXk5Ojbb7/ViRMnFBAQoLfeeqvAZ/oAMAOXxgCUaUeOHFF8fLy2bt2qzMxM/fzzzwoJCVHXrl01ceJENW3a1NslAvAir14a++KLL9S7d2/VrFlTNptNa9eu/dV1kpKSdP/998tut6tBgwZavny5x+sEUHrdc889WrZsmY4cOaLs7Gzl5uYqLS1N77zzDiEIgHeD0KVLlxQeHq5FixYVqv/x48fVq1cvdevWTSkpKRozZoxGjBihjRs3erhSAABQFpWYS2M2m01r1qxR3759b9pnwoQJWr9+vcsTUwcMGKDz588rISGhGKoEAABlSamaLJ2cnKzIyEiXtqioKI0ZM+am6+Tk5Li8jTo/P19nz57VXXfdxQRJAABKCcuydOHCBdWsWbNIX75cqoJQRkaGgoODXdqCg4OVnZ2tK1euqEKFCjesEx8fr+nTpxdXiQAAwIPS09MLfBfi7SpVQeh2TJo0SbGxsc6fs7KyVLt2baWnpyswMNCLlQEAgMLKzs6Ww+FQpUqVinS7pSoIhYSE3PBgtMzMTAUGBhZ4NkiS7Ha77Hb7De2BgYEEIQAASpmintZSqp4sHRERocTERJe2TZs2KSIiwksVAQCA0syrQejixYtKSUlRSkqKpF9uj09JSVFaWpqkXy5rxcTEOPs//vjjSk1N1fPPP6+DBw/qjTfe0AcffKCxY8d6o3wAAFDKeTUI7dq1S/fdd5/uu+8+SVJsbKzuu+8+TZ06VZJ08uRJZyiSpLp162r9+vXatGmTwsPDNXfuXL311luKiorySv0AAKB0KzHPESou2dnZCgoKUlZWFnOEAAAoJTz1/V2q5ggBAAAUJYIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLG8HoQWLVqksLAw+fv7q127dtqxY8ct+8+fP1+NGjVShQoV5HA4NHbsWP3888/FVC0AAChLvBqEVq5cqdjYWMXFxWnPnj0KDw9XVFSUTp06VWD/9957TxMnTlRcXJwOHDigpUuXauXKlXrhhReKuXIAAFAWeDUIzZs3TyNHjtSwYcPUtGlTLV68WAEBAVq2bFmB/b/88kt17NhRgwYNUlhYmHr06KGBAwf+6lkkAACAgngtCOXm5mr37t2KjIz8dzE+PoqMjFRycnKB63To0EG7d+92Bp/U1FRt2LBBPXv2vOl+cnJylJ2d7fIBAACQpHLe2vGZM2eUl5en4OBgl/bg4GAdPHiwwHUGDRqkM2fOqFOnTrIsS9euXdPjjz9+y0tj8fHxmj59epHWDgAAygavT5Z2R1JSkmbNmqU33nhDe/bs0erVq7V+/XrNmDHjputMmjRJWVlZzk96enoxVgwAAEoyr50Rqlatmnx9fZWZmenSnpmZqZCQkALXmTJligYPHqwRI0ZIkpo3b65Lly5p1KhRmjx5snx8bsx1drtddru96A8AAACUel47I+Tn56dWrVopMTHR2Zafn6/ExERFREQUuM7ly5dvCDu+vr6SJMuyPFcsAAAok7x2RkiSYmNjNWTIELVu3Vpt27bV/PnzdenSJQ0bNkySFBMTo1q1aik+Pl6S1Lt3b82bN0/33Xef2rVrp6NHj2rKlCnq3bu3MxABAAAUlleDUP/+/XX69GlNnTpVGRkZatmypRISEpwTqNPS0lzOAL344ouy2Wx68cUX9eOPP6p69erq3bu3/vjHP3rrEAAAQClmswy7ppSdna2goCBlZWUpMDDQ2+UAAIBC8NT3d6m6awwAAKAoEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjHXHQSg7O1tr167VgQMHbmv9RYsWKSwsTP7+/mrXrp127Nhxy/7nz5/X6NGjFRoaKrvdroYNG2rDhg23tW8AAGA2t4NQdHS0Fi5cKEm6cuWKWrdurejoaLVo0UIfffSRW9tauXKlYmNjFRcXpz179ig8PFxRUVE6depUgf1zc3PVvXt3nThxQqtWrdKhQ4e0ZMkS1apVy93DAAAAcD8IffHFF+rcubMkac2aNbIsS+fPn9eCBQs0c+ZMt7Y1b948jRw5UsOGDVPTpk21ePFiBQQEaNmyZQX2X7Zsmc6ePau1a9eqY8eOCgsLU5cuXRQeHu7uYQAAALgfhLKyslS1alVJUkJCgh5++GEFBASoV69eOnLkSKG3k5ubq927dysyMvLfxfj4KDIyUsnJyQWu88knnygiIkKjR49WcHCwmjVrplmzZikvL++m+8nJyVF2drbLBwAAQLqNIORwOJScnKxLly4pISFBPXr0kCSdO3dO/v7+hd7OmTNnlJeXp+DgYJf24OBgZWRkFLhOamqqVq1apby8PG3YsEFTpkzR3Llzb3kmKj4+XkFBQc6Pw+EodI0AAKBsczsIjRkzRo888ojuvvtu1axZU127dpX0yyWz5s2bF3V9LvLz81WjRg29+eabatWqlfr376/Jkydr8eLFN11n0qRJysrKcn7S09M9WiMAACg9yrm7wpNPPqm2bdsqPT1d3bt3l4/PL1mqXr16bs0Rqlatmnx9fZWZmenSnpmZqZCQkALXCQ0NVfny5eXr6+tsa9KkiTIyMpSbmys/P78b1rHb7bLb7YWuCwAAmOO2bp9v3bq1fve736lixYrKy8tTSkqKOnTooI4dOxZ6G35+fmrVqpUSExOdbfn5+UpMTFRERESB63Ts2FFHjx5Vfn6+s+3w4cMKDQ0tMAQBAADcym1dGlu6dKkkKS8vT126dNH9998vh8OhpKQkt7YVGxurJUuW6C9/+YsOHDigJ554QpcuXdKwYcMkSTExMZo0aZKz/xNPPKGzZ8/q2Wef1eHDh7V+/XrNmjVLo0ePdvcwAAAA3L80tmrVKj366KOSpHXr1un48eM6ePCg/vrXv2ry5Mnavn17obfVv39/nT59WlOnTlVGRoZatmyphIQE5wTqtLQ056U36ZeJ2hs3btTYsWPVokUL1apVS88++6wmTJjg7mEAAADIZlmW5c4K/v7+Onr0qO6++26NGjVKAQEBmj9/vo4fP67w8PASf3t6dna2goKClJWVpcDAQG+XAwAACsFT399uXxoLDg7W/v37lZeXp4SEBHXv3l2SdPnyZZdJzAAAACWd25fGhg0bpujoaIWGhspmszkfiPj111+rcePGRV4gAACAp7gdhKZNm6ZmzZopPT1d/fr1c96a7uvrq4kTJxZ5gQAAAJ7i9hyh0o45QgAAlD4lZo6QJG3ZskW9e/dWgwYN1KBBA/Xp00dbt24tsqIAAACKg9tB6G9/+5siIyMVEBCgZ555Rs8884wqVKig3/zmN3rvvfc8USMAAIBHuH1prEmTJho1apTGjh3r0j5v3jwtWbJEBw4cKNICixqXxgAAKH1KzKWx1NRU9e7d+4b2Pn366Pjx40VSFAAAQHFwOwg5HA6X94Nd99lnn8nhcBRJUQAAAMXB7dvnn3vuOT3zzDPOF61K0vbt27V8+XK99tprRV4gAACAp7gdhJ544gmFhIRo7ty5+uCDDyT9Mm9o5cqVevDBB4u8QAAAAE/hOUIAAKDEKzGTpQEAAMqKQl0aq1Klimw2W6E2ePbs2TsqCAAAoLgUKgjNnz/fw2UAAAAUv0IFoSFDhni6DgAAgGLHHCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMZy+xUbv/vd7wp8ppDNZpO/v78aNGigQYMGqVGjRkVSIAAAgKe4fUYoKChImzdv1p49e2Sz2WSz2bR3715t3rxZ165d08qVKxUeHq7t27d7ol4AAIAi4/YZoZCQEA0aNEgLFy6Uj88vOSo/P1/PPvusKlWqpBUrVujxxx/XhAkTtG3btiIvGAAAoKi4/dLV6tWra/v27WrYsKFL++HDh9WhQwedOXNG+/btU+fOnXX+/PmirLVI8NJVAABKnxLz0tVr167p4MGDN7QfPHhQeXl5kiR/f/9Cv5sMAADAW9y+NDZ48GANHz5cL7zwgtq0aSNJ2rlzp2bNmqWYmBhJ0pYtW3TvvfcWbaUAAABFzO0g9Oqrryo4OFgvv/yyMjMzJUnBwcEaO3asJkyYIEnq0aOHfvvb3xZtpQAAAEXM7TlC/yk7O1uSStVcG+YIAQBQ+njq+9vtM0L/iSABAABKM7cnS2dmZmrw4MGqWbOmypUrJ19fX5cPAABAaeH2GaGhQ4cqLS1NU6ZMUWhoKHeHAQCAUsvtILRt2zZt3bpVLVu29EA5AAAAxcftS2MOh0N3ML8aAACgxHA7CM2fP18TJ07UiRMnPFAOAABA8XH70lj//v11+fJl1a9fXwEBASpfvrzL8rNnzxZZcQAAAJ7kdhCaP3++B8oAAAAofm4HoSFDhniiDgAAgGJXqCCUnZ3tfHji9adJ3wwPWQQAAKVFoYJQlSpVdPLkSdWoUUOVK1cu8NlBlmXJZrM530APAABQ0hUqCG3evFlVq1aVJH3++eceLQgAAKC43NFLV0sjXroKAEDpU6Jeunr+/Hnt2LFDp06dUn5+vsuymJiYIikMAADA09wOQuvWrdMjjzyiixcvKjAw0GW+kM1mIwgBAIBSw+0nSz/33HN67LHHdPHiRZ0/f17nzp1zfniYIgAAKE3cDkI//vijnnnmGQUEBHiiHgAAgGLjdhCKiorSrl27PFELAABAsXJ7jlCvXr00fvx47d+/X82bN7/hXWN9+vQpsuIAAAA8ye3b5318bn4SqTQ8UJHb5wEAKH1KzO3z/327PAAAQGnl9hwhAACAsqJQZ4QWLFigUaNGyd/fXwsWLLhl32eeeaZICgMAAPC0Qs0Rqlu3rnbt2qW77rpLdevWvfnGbDalpqYWaYFFjTlCAACUPl6dI3T8+PEC/wwAAFCaMUcIAAAY67ZeuvrDDz/ok08+UVpamnJzc12WzZs3r0gKAwAA8DS3g1BiYqL69OmjevXq6eDBg2rWrJlOnDghy7J0//33e6JGAAAAj3D70tikSZM0btw47du3T/7+/vroo4+Unp6uLl26qF+/fp6oEQAAwCPcDkIHDhxQTEyMJKlcuXK6cuWKKlasqJdeeklz5swp8gIBAAA8xe0g9D//8z/OeUGhoaE6duyYc9mZM2eKrjIAAAAPc3uOUPv27bVt2zY1adJEPXv21HPPPad9+/Zp9erVat++vSdqBAAA8Ai3g9C8efN08eJFSdL06dN18eJFrVy5Uvfccw93jAEAgFLFrSCUl5enH374QS1atJD0y2WyxYsXe6QwAAAAT3NrjpCvr6969Oihc+fOFWkRixYtUlhYmPz9/dWuXTvt2LGjUOutWLFCNptNffv2LdJ6AACAGdyeLN2sWbMifZ/YypUrFRsbq7i4OO3Zs0fh4eGKiorSqVOnbrneiRMnNG7cOHXu3LnIagEAAGZxOwjNnDlT48aN06effqqTJ08qOzvb5eOuefPmaeTIkRo2bJiaNm2qxYsXKyAgQMuWLbvpOnl5eXrkkUc0ffp01atXz+19AgAASLcxWbpnz56SpD59+shmsznbLcuSzWZTXl5eobeVm5ur3bt3a9KkSc42Hx8fRUZGKjk5+abrvfTSS6pRo4aGDx+urVu33nIfOTk5ysnJcf58O2ENAACUTW4Hoc8//7zIdn7mzBnl5eUpODjYpT04OFgHDx4scJ1t27Zp6dKlSklJKdQ+4uPjNX369DstFQAAlEFuB6G6devK4XC4nA2SfjkjlJ6eXmSFFeTChQsaPHiwlixZomrVqhVqnUmTJik2Ntb5c3Z2thwOh6dKBAAApchtBaGTJ0+qRo0aLu1nz55V3bp13bo0Vq1aNfn6+iozM9OlPTMzUyEhITf0P3bsmE6cOKHevXs72/Lz8yX98rqPQ4cOqX79+i7r2O122e32QtcEAADM4fZk6etzgf7bxYsX5e/v79a2/Pz81KpVKyUmJjrb8vPzlZiYqIiIiBv6N27cWPv27VNKSorz06dPH3Xr1k0pKSmc6QEAAG4p9Bmh65eXbDabpkyZooCAAOeyvLw8ff3112rZsqXbBcTGxmrIkCFq3bq12rZtq/nz5+vSpUsaNmyYJCkmJka1atVSfHy8/P391axZM5f1K1euLEk3tAMAAPyaQgehvXv3SvrljNC+ffvk5+fnXObn56fw8HCNGzfO7QL69++v06dPa+rUqcrIyFDLli2VkJDgnECdlpYmHx+3T1wBAAD8KptlWZY7KwwbNkyvvfaaAgMDPVWTR2VnZysoKEhZWVml9hgAADCNp76/3Z4s/fbbbxfZzgEAALyJa04AAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxioRQWjRokUKCwuTv7+/2rVrpx07dty075IlS9S5c2dVqVJFVapUUWRk5C37AwAA3IzXg9DKlSsVGxuruLg47dmzR+Hh4YqKitKpU6cK7J+UlKSBAwfq888/V3JyshwOh3r06KEff/yxmCsHAAClnc2yLMubBbRr105t2rTRwoULJUn5+flyOBx6+umnNXHixF9dPy8vT1WqVNHChQsVExPzq/2zs7MVFBSkrKwsBQYG3nH9AADA8zz1/e3VM0K5ubnavXu3IiMjnW0+Pj6KjIxUcnJyobZx+fJlXb16VVWrVi1weU5OjrKzs10+AAAAkpeD0JkzZ5SXl6fg4GCX9uDgYGVkZBRqGxMmTFDNmjVdwtR/io+PV1BQkPPjcDjuuG4AAFA2eH2O0J2YPXu2VqxYoTVr1sjf37/APpMmTVJWVpbzk56eXsxVAgCAkqqcN3derVo1+fr6KjMz06U9MzNTISEht1z3lVde0ezZs/XZZ5+pRYsWN+1nt9tlt9uLpF4AAFC2ePWMkJ+fn1q1aqXExERnW35+vhITExUREXHT9V5++WXNmDFDCQkJat26dXGUCgAAyiCvnhGSpNjYWA0ZMkStW7dW27ZtNX/+fF26dEnDhg2TJMXExKhWrVqKj4+XJM2ZM0dTp07Ve++9p7CwMOdcoooVK6pixYpeOw4AAFD6eD0I9e/fX6dPn9bUqVOVkZGhli1bKiEhwTmBOi0tTT4+/z5x9ac//Um5ubn6/e9/77KduLg4TZs2rThLBwAApZzXnyNU3HiOEAAApU+ZfI4QAACANxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABirRAShRYsWKSwsTP7+/mrXrp127Nhxy/4ffvihGjduLH9/fzVv3lwbNmwopkoBAEBZ4vUgtHLlSsXGxiouLk579uxReHi4oqKidOrUqQL7f/nllxo4cKCGDx+uvXv3qm/fvurbt6++/fbbYq4cAACUdjbLsixvFtCuXTu1adNGCxculCTl5+fL4XDo6aef1sSJE2/o379/f126dEmffvqps619+/Zq2bKlFi9e/Kv7y87OVlBQkLKyshQYGFh0BwIAADzGU9/fXj0jlJubq927dysyMtLZ5uPjo8jISCUnJxe4TnJyskt/SYqKirppfwAAgJsp582dnzlzRnl5eQoODnZpDw4O1sGDBwtcJyMjo8D+GRkZBfbPyclRTk6O8+esrCxJvyRLAABQOlz/3i7qC1leDULFIT4+XtOnT7+h3eFweKEaAABwJ3766ScFBQUV2fa8GoSqVasmX19fZWZmurRnZmYqJCSkwHVCQkLc6j9p0iTFxsY6fz5//rzq1KmjtLS0Iv1Fwn3Z2dlyOBxKT09nvlYJwHiUHIxFycFYlBxZWVmqXbu2qlatWqTb9WoQ8vPzU6tWrZSYmKi+fftK+mWydGJiop566qkC14mIiFBiYqLGjBnjbNu0aZMiIiIK7G+322W3229oDwoK4i91CREYGMhYlCCMR8nBWJQcjEXJ4eNTtNObvX5pLDY2VkOGDFHr1q3Vtm1bzZ8/X5cuXdKwYcMkSTExMapVq5bi4+MlSc8++6y6dOmiuXPnqlevXlqxYoV27dqlN99805uHAQAASiGvB6H+/fvr9OnTmjp1qjIyMtSyZUslJCQ4J0SnpaW5pL8OHTrovffe04svvqgXXnhB99xzj9auXatmzZp56xAAAEAp5fUgJElPPfXUTS+FJSUl3dDWr18/9evX77b2ZbfbFRcXV+DlMhQvxqJkYTxKDsai5GAsSg5PjYXXH6gIAADgLV5/xQYAAIC3EIQAAICxCEIAAMBYBCEAAGCsMhmEFi1apLCwMPn7+6tdu3basWPHLft/+OGHaty4sfz9/dW8eXNt2LChmCot+9wZiyVLlqhz586qUqWKqlSposjIyF8dO7jH3X8b161YsUI2m8354FPcOXfH4vz58xo9erRCQ0Nlt9vVsGFD/q8qIu6Oxfz589WoUSNVqFBBDodDY8eO1c8//1xM1ZZdX3zxhXr37q2aNWvKZrNp7dq1v7pOUlKS7r//ftntdjVo0EDLly93f8dWGbNixQrLz8/PWrZsmfXdd99ZI0eOtCpXrmxlZmYW2H/79u2Wr6+v9fLLL1v79++3XnzxRat8+fLWvn37irnyssfdsRg0aJC1aNEia+/evdaBAwesoUOHWkFBQdYPP/xQzJWXTe6Ox3XHjx+3atWqZXXu3Nl68MEHi6fYMs7dscjJybFat25t9ezZ09q2bZt1/PhxKykpyUpJSSnmyssed8fi3Xfftex2u/Xuu+9ax48ftzZu3GiFhoZaY8eOLebKy54NGzZYkydPtlavXm1JstasWXPL/qmpqVZAQIAVGxtr7d+/33r99dctX19fKyEhwa39lrkg1LZtW2v06NHOn/Py8qyaNWta8fHxBfaPjo62evXq5dLWrl076w9/+INH6zSBu2Px365du2ZVqlTJ+stf/uKpEo1yO+Nx7do1q0OHDtZbb71lDRkyhCBURNwdiz/96U9WvXr1rNzc3OIq0RjujsXo0aOtBx54wKUtNjbW6tixo0frNE1hgtDzzz9v3XvvvS5t/fv3t6KiotzaV5m6NJabm6vdu3crMjLS2ebj46PIyEglJycXuE5ycrJLf0mKioq6aX8Uzu2MxX+7fPmyrl69WuQv2DPR7Y7HSy+9pBo1amj48OHFUaYRbmcsPvnkE0VERGj06NEKDg5Ws2bNNGvWLOXl5RVX2WXS7YxFhw4dtHv3bufls9TUVG3YsEE9e/Yslprxb0X1/V0inixdVM6cOaO8vDzn6zmuCw4O1sGDBwtcJyMjo8D+GRkZHqvTBLczFv9twoQJqlmz5g1/0eG+2xmPbdu2aenSpUpJSSmGCs1xO2ORmpqqzZs365FHHtGGDRt09OhRPfnkk7p69ari4uKKo+wy6XbGYtCgQTpz5ow6deoky7J07do1Pf7443rhhReKo2T8h5t9f2dnZ+vKlSuqUKFCobZTps4IoeyYPXu2VqxYoTVr1sjf39/b5RjnwoULGjx4sJYsWaJq1ap5uxzj5efnq0aNGnrzzTfVqlUr9e/fX5MnT9bixYu9XZpxkpKSNGvWLL3xxhvas2ePVq9erfXr12vGjBneLg23qUydEapWrZp8fX2VmZnp0p6ZmamQkJAC1wkJCXGrPwrndsbiuldeeUWzZ8/WZ599phYtWniyTGO4Ox7Hjh3TiRMn1Lt3b2dbfn6+JKlcuXI6dOiQ6tev79miy6jb+bcRGhqq8uXLy9fX19nWpEkTZWRkKDc3V35+fh6tuay6nbGYMmWKBg8erBEjRkiSmjdvrkuXLmnUqFGaPHmyy0vC4Vk3+/4ODAws9NkgqYydEfLz81OrVq2UmJjobMvPz1diYqIiIiIKXCciIsKlvyRt2rTppv1ROLczFpL08ssva8aMGUpISFDr1q2Lo1QjuDsejRs31r59+5SSkuL89OnTR926dVNKSoocDkdxll+m3M6/jY4dO+ro0aPOMCpJhw8fVmhoKCHoDtzOWFy+fPmGsHM9oFq8urNYFdn3t3vzuEu+FStWWHa73Vq+fLm1f/9+a9SoUVblypWtjIwMy7Isa/DgwdbEiROd/bdv326VK1fOeuWVV6wDBw5YcXFx3D5fRNwdi9mzZ1t+fn7WqlWrrJMnTzo/Fy5c8NYhlCnujsd/466xouPuWKSlpVmVKlWynnrqKevQoUPWp59+atWoUcOaOXOmtw6hzHB3LOLi4qxKlSpZ77//vpWammr94x//sOrXr29FR0d76xDKjAsXLlh79+619u7da0my5s2bZ+3du9f6/vvvLcuyrIkTJ1qDBw929r9++/z48eOtAwcOWIsWLeL2+etef/11q3bt2pafn5/Vtm1b66uvvnIu69KlizVkyBCX/h988IHVsGFDy8/Pz7r33nut9evXF3PFZZc7Y1GnTh1L0g2fuLi44i+8jHL338Z/IggVLXfH4ssvv7TatWtn2e12q169etYf//hH69q1a8VcddnkzlhcvXrVmjZtmlW/fn3L39/fcjgc1pNPPmmdO3eu+AsvYz7//PMCvwOu//6HDBlidenS5YZ1WrZsafn5+Vn16tWz3n77bbf3a7MszuUBAAAzlak5QgAAAO4gCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBMA4SUlJstlsOn/+vLdLAeBlBCEAAGAsghAAADAWQQhAscvPz1d8fLzq1q2rChUqKDw8XKtWrZL078tW69evV4sWLeTv76/27dvr22+/ddnGRx99pHvvvVd2u11hYWGaO3euy/KcnBxNmDBBDodDdrtdDRo00NKlS1367N69W61bt1ZAQIA6dOigQ4cOOZd988036tatmypVqqTAwEC1atVKu3bt8tBvBIC3EIQAFLv4+Hi98847Wrx4sb777juNHTtWjz76qLZs2eLsM378eM2dO1c7d+5U9erV1bt3b129elXSLwEmOjpaAwYM0L59+zRt2jRNmTJFy5cvd64fExOj999/XwsWLNCBAwf05z//WRUrVnSpY/LkyZo7d6527dqlcuXK6bHHHnMue+SRR3T33Xdr586d2r17tyZOnKjy5ct79hcDoPjd6dtiAcAdP//8sxUQEGB9+eWXLu3Dhw+3Bg4c6HwD9YoVK5zLfvrpJ6tChQrWypUrLcuyrEGDBlndu3d3WX/8+PFW06ZNLcuyrEOHDlmSrE2bNhVYw/V9fPbZZ8629evXW5KsK1euWJZlWZUqVbKWL19+5wcMoETjjBCAYnX06FFdvnxZ3bt3V8WKFZ2fd955R8eOHXP2i4iIcP65atWqatSokQ4cOCBJOnDggDp27Oiy3Y4dO+rIkSPKy8tTSkqKfH191aVLl1vW0qJFC+efQ0NDJUmnTp2SJMXGxmrEiBGKjIzU7NmzXWoDUHYQhAAUq4sXL0qS1q9fr5SUFOdn//79znlCd6pChQqF6vefl7psNpukX+YvSdK0adP03XffqVevXtq8ebOaNm2qNWvWFEl9AEoOghCAYtW0aVPZ7XalpaWpQYMGLh+Hw+Hs99VXXzn/fO7cOR0+fFhNmjSRJDVp0kTbt2932e727dvVsGFD+fr6qnnz5srPz3eZc3Q7GjZsqLFjx+of//iHHnroIb399tt3tD0AJU85bxcAwCyVKlXSuHHjNHbsWOXn56tTp07KysrS9u3bFRgYqDp16kiSXnrpJd11110KDg7W5MmTVa1aNfXt21eS9Nxzz6lNmzaaMWOG+vfvr+TkZC1cuFBvvPGGJCksLExDhgzRY489pgULFig8PFzff/+9Tp06pejo6F+t8cqVKxo/frx+//vfq27duvrhhx+0c+dOPfzwwx77vQDwEm9PUgJgnvz8fGv+/PlWo0aNrPLly1vVq1e3oqKirC1btjgnMq9bt8669957LT8/P6tt27bWN99847KNVatWWU2bNrXKly9v1a5d2/q///s/l+VXrlyxxo4da4WGhlp+fn5WgwYNrGXLllmW9e/J0ufOnXP237t3ryXJOn78uJWTk2MNGDDAcjgclp+fn1WzZk3rqaeeck6kBlB22CzLsrycxQDAKSkpSd26ddO5c+dUuXJlb5cDoIxjjhAAADAWQQgAABiLS2MAAMBYnBECAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMb6/8nX8PXTaBdlAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# # cifar_resnet.py\n",
        "net = net.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "PATH = './cifar_net_Adam.pth'\n",
        "for beta in betas:\n",
        "    beta_2 = beta\n",
        "    for batchSize in batchSizes:\n",
        "        batchsize = batchSize\n",
        "        #alex change 2\n",
        "        # net = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=False)\n",
        "        # net = net.to(device)\n",
        "        optimizer = optim.Adam(net.parameters(), lr=0.001, betas=(beta_1, beta), eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "        #alex change 3\n",
        "        # trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchsize,\n",
        "        #                                   shuffle=True, num_workers=8,  pin_memory=True)\n",
        "\n",
        "        # testloader = torch.utils.data.DataLoader(testset, batch_size=batchsize,\n",
        "        #                                  shuffle=False, num_workers=8,  pin_memory=True)\n",
        "        train(net, epochs, \"Exp1-training-loss-beta1=\"+str(beta_1)+\";beta2=\"+str(beta)+\";bs=\"+str(batchSize), \"Exp1-test-accuracy-beta1=\"+str(beta_1)+\";beta2=\"+str(beta_2)+\";bs=\"+str(batchsize), \"Exp1-train-accuracy-beta1=\"+str(beta_1)+\";beta2=\"+str(beta_2)+\";bs=\"+str(batchsize), 0.001, batchsize, device)\n",
        "        torch.save(net.state_dict(), PATH)\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZHDhvPxEumi-"
      },
      "outputs": [],
      "source": [
        "# cifar_resnet_SGD.py\n",
        "net = net.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=beta_1, dampening=0, weight_decay=0, nesterov=False)\n",
        "PATH = './cifar_net_SGD.pth'\n",
        "for batchSize in batchSizes:\n",
        "    train(net, epochs, \"Exp1-training-loss-beta1=\"+str(beta_1)+\";bs=\"+str(batchSize), \"Exp1-test-accuracy-beta1=\"+str(beta_1)+\";bs=\"+str(batchSize), \"Exp1-train-accuracy-beta1=\"+str(beta_1)+\";bs=\"+str(batchSize), 0.001, batchSize, device)\n",
        "    torch.save(net.state_dict(), PATH)\n",
        "print('Finished Training')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}