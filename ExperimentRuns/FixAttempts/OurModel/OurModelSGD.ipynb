{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexistaylor3/CS536_FinalProject/blob/main/cifar_new_resnet_original.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHDpbozmN-bM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.layer1 = self._make_layer(block, 64,  layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        # init\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = [block(self.inplanes, planes, stride, downsample)]\n",
        "        self.inplanes = planes * block.expansion\n",
        "\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def resnet18_cifar10(num_classes=10):\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes)\n",
        "\n",
        "\n",
        "# Example model\n",
        "model = resnet18_cifar10()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "Ah19jrJqNVHV",
        "outputId": "f404a018-30d8-47ea-85d3-baa87fa030d4"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Batch Size: 32\n",
        "Beta 2: 0.99\n",
        "\"\"\"\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "\n",
        "# functions to show an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "def show_some_pictures(j ):\n",
        "    # get some random training images\n",
        "    dataiter = iter(trainloader)\n",
        "    images, labels = dataiter.next()\n",
        "\n",
        "    # show images\n",
        "    imshow(torchvision.utils.make_grid(images))\n",
        "    # print labels\n",
        "    print(' '.join('%5s' % classes[labels[j]] for j in range(j)))\n",
        "\n",
        "\n",
        "def random_test():\n",
        "    dataiter = iter(testloader)\n",
        "    images, labels = dataiter.next()\n",
        "\n",
        "    # print images\n",
        "    imshow(torchvision.utils.make_grid(images))\n",
        "    print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "    net = Net()\n",
        "    net.load_state_dict(torch.load(PATH))\n",
        "    outputs = net(images)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                                  for j in range(4)))\n",
        "\n",
        "def train(net, noe, filepath_trainloss, filepath_testacc, filepath_trainacc, initial_lr,  batchsize, device):\n",
        "    doc = open(filepath_trainloss+'.txt', \"w\")\n",
        "    doc2 = open(filepath_testacc+'.txt', \"w\")\n",
        "    doc3 = open(filepath_trainacc+'.txt', \"w\")\n",
        "    check_interval=1000\n",
        "    batch_number = int(6000*8/(batchsize*check_interval))\n",
        "    #print(batch_number)\n",
        "    training_loss_vec = [] #np.zeros(noe*check_interval)\n",
        "    train_acc_vec = [] #np.zeros(noe*check_interval)\n",
        "    test_acc_vec = [] #np.zeros(noe*check_interval)\n",
        "    for epoch in range(noe):  # loop over the dataset multiple times\n",
        "        time_begin  = time.time()\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data[0].to(device, non_blocking=True), data[1].to(device, non_blocking=True)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            if i % check_interval == (check_interval-1):    # print every 2000 mini-batches\n",
        "                time_end = time.time()\n",
        "                time_elapsed = time_end - time_begin\n",
        "                time_begin = time.time()\n",
        "                print('[%d, %5d] loss: %.3f, Ça coûte %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / check_interval, time_elapsed))\n",
        "                training_loss_vec.append(running_loss/check_interval)\n",
        "                train_acc = train_accuracy(net)\n",
        "                train_acc_vec.append(train_acc)\n",
        "                test_acc = test_accuracy(net)\n",
        "                test_acc_vec.append(test_acc)\n",
        "                print(running_loss / check_interval, file=doc)\n",
        "                print(test_acc, file=doc2)\n",
        "                print(train_acc, file=doc3)\n",
        "                running_loss = 0.0\n",
        "        if epoch % 1 == 0:\n",
        "            for p in optimizer.param_groups:\n",
        "                p['lr'] = initial_lr/np.sqrt(1+epoch)\n",
        "    doc.close()\n",
        "    doc2.close()\n",
        "\n",
        "    xvar=np.arange(noe*batch_number)/batch_number\n",
        "    #plt.subplot(122)\n",
        "    plt.figure(1)\n",
        "    plt.title(\"Training Loss\", fontsize=15)\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('training loss')\n",
        "    plt.plot(xvar, np.array(training_loss_vec))\n",
        "    plt.savefig(filepath_trainloss+'.png')\n",
        "\n",
        "    #plt.subplot(122)\n",
        "    plt.figure(2)\n",
        "    plt.title(\"Test Accuracy\", fontsize=15)\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('test accuracy(%)')\n",
        "    plt.plot(xvar, np.array(test_acc_vec), label=\"Test accuracy\")\n",
        "    plt.legend()\n",
        "    plt.savefig(filepath_testacc + '.png')\n",
        "\n",
        "    #plt.subplot(122)\n",
        "    plt.figure(2)\n",
        "    plt.title(\"Training and Test Accuracy\", fontsize=15)\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('training accuracy(%)')\n",
        "    plt.plot(xvar, np.array(train_acc_vec), label=\"Training accuracy\")\n",
        "    plt.legend()\n",
        "    plt.savefig(filepath_trainacc + '.png')\n",
        "\n",
        "def train_accuracy(net):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in trainloader:\n",
        "            images, labels = data[0].to(device, non_blocking=True), data[1].to(device, non_blocking=True)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "def test_accuracy(net):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[0].to(device, non_blocking=True), data[1].to(device, non_blocking=True)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#device = torch.device(\"cpu\")\n",
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    print('Memory Usage:')\n",
        "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
        "\n",
        "batchsize=32\n",
        "# data sets\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchsize,\n",
        "                                          shuffle=True, num_workers=1 , pin_memory=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batchsize,\n",
        "                                         shuffle=False, num_workers=1 , pin_memory=True)\n",
        "\n",
        "beta_1 = 0.0\n",
        "beta_2 = 0.99\n",
        "\n",
        "# resnet\n",
        "net = resnet18_cifar10(num_classes=10)\n",
        "net.eval()\n",
        "\n",
        "net = net.to(device, non_blocking=True)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adam(net.parameters(), lr=0.001, betas=(beta_1, beta_2), eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=beta_1, dampening=0, weight_decay=0, nesterov=False)\n",
        "train(net, 100, \"Exp1-training-loss-beta1=\"+str(beta_1)+\";bs=\"+str(batchsize), \"Exp1-test-accuracy-beta1=\"+str(beta_1)+\";bs=\"+str(batchsize), \"Exp1-train-accuracy-beta1=\"+str(beta_1)+\";bs=\"+str(batchsize), 0.001, batchsize, device)\n",
        "print('Finished Training')\n",
        "PATH = './cifar_net.pth'\n",
        "torch.save(net.state_dict(), PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Batch Size: 512\n",
        "Beta 2: 0.99\n",
        "\"\"\"\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "\n",
        "# functions to show an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "def show_some_pictures(j ):\n",
        "    # get some random training images\n",
        "    dataiter = iter(trainloader)\n",
        "    images, labels = dataiter.next()\n",
        "\n",
        "    # show images\n",
        "    imshow(torchvision.utils.make_grid(images))\n",
        "    # print labels\n",
        "    print(' '.join('%5s' % classes[labels[j]] for j in range(j)))\n",
        "\n",
        "\n",
        "def random_test():\n",
        "    dataiter = iter(testloader)\n",
        "    images, labels = dataiter.next()\n",
        "\n",
        "    # print images\n",
        "    imshow(torchvision.utils.make_grid(images))\n",
        "    print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "    net = Net()\n",
        "    net.load_state_dict(torch.load(PATH))\n",
        "    outputs = net(images)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                                  for j in range(4)))\n",
        "\n",
        "def train(net, noe, filepath_trainloss, filepath_testacc, filepath_trainacc, initial_lr,  batchsize, device):\n",
        "    doc = open(filepath_trainloss+'.txt', \"w\")\n",
        "    doc2 = open(filepath_testacc+'.txt', \"w\")\n",
        "    doc3 = open(filepath_trainacc+'.txt', \"w\")\n",
        "    check_interval=50\n",
        "    batch_number = int(6000*8/(batchsize*check_interval))\n",
        "    #print(batch_number)\n",
        "    training_loss_vec = [] #np.zeros(noe*check_interval)\n",
        "    train_acc_vec = [] #np.zeros(noe*check_interval)\n",
        "    test_acc_vec = [] #np.zeros(noe*check_interval)\n",
        "    for epoch in range(noe):  # loop over the dataset multiple times\n",
        "        time_begin  = time.time()\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data[0].to(device, non_blocking=True), data[1].to(device, non_blocking=True)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            if i % check_interval == (check_interval-1):    # print every 2000 mini-batches\n",
        "                time_end = time.time()\n",
        "                time_elapsed = time_end - time_begin\n",
        "                time_begin = time.time()\n",
        "                print('[%d, %5d] loss: %.3f, Ça coûte %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / check_interval, time_elapsed))\n",
        "                training_loss_vec.append(running_loss/check_interval)\n",
        "                train_acc = train_accuracy(net)\n",
        "                train_acc_vec.append(train_acc)\n",
        "                test_acc = test_accuracy(net)\n",
        "                test_acc_vec.append(test_acc)\n",
        "                print(running_loss / check_interval, file=doc)\n",
        "                print(test_acc, file=doc2)\n",
        "                print(train_acc, file=doc3)\n",
        "                running_loss = 0.0\n",
        "        if epoch % 1 == 0:\n",
        "            for p in optimizer.param_groups:\n",
        "                p['lr'] = initial_lr/np.sqrt(1+epoch)\n",
        "    doc.close()\n",
        "    doc2.close()\n",
        "\n",
        "    xvar=np.arange(len(train_acc_vec))\n",
        "    #plt.subplot(122)\n",
        "    plt.figure(1)\n",
        "    plt.title(\"Training Loss\", fontsize=15)\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('training loss')\n",
        "    plt.plot(xvar, np.array(training_loss_vec))\n",
        "    plt.savefig(filepath_trainloss+'.png')\n",
        "\n",
        "    #plt.subplot(122)\n",
        "    plt.figure(2)\n",
        "    plt.title(\"Test Accuracy\", fontsize=15)\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('test accuracy(%)')\n",
        "    plt.plot(xvar, np.array(test_acc_vec), label=\"Test accuracy\")\n",
        "    plt.legend()\n",
        "    plt.savefig(filepath_testacc + '.png')\n",
        "\n",
        "    #plt.subplot(122)\n",
        "    plt.figure(2)\n",
        "    plt.title(\"Training and Test Accuracy\", fontsize=15)\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('training accuracy(%)')\n",
        "    plt.plot(xvar, np.array(train_acc_vec), label=\"Training accuracy\")\n",
        "    plt.legend()\n",
        "    plt.savefig(filepath_trainacc + '.png')\n",
        "\n",
        "def train_accuracy(net):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in trainloader:\n",
        "            images, labels = data[0].to(device, non_blocking=True), data[1].to(device, non_blocking=True)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "def test_accuracy(net):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[0].to(device, non_blocking=True), data[1].to(device, non_blocking=True)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#device = torch.device(\"cpu\")\n",
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    print('Memory Usage:')\n",
        "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
        "\n",
        "batchsize=512\n",
        "# data sets\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchsize,\n",
        "                                          shuffle=True, num_workers=1 , pin_memory=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batchsize,\n",
        "                                         shuffle=False, num_workers=1 , pin_memory=True)\n",
        "\n",
        "beta_1 = 0.0\n",
        "beta_2 = 0.99\n",
        "\n",
        "# resnet\n",
        "net = resnet18_cifar10(num_classes=10)\n",
        "net.eval()\n",
        "\n",
        "net = net.to(device, non_blocking=True)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adam(net.parameters(), lr=0.001, betas=(beta_1, beta_2), eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=beta_1, dampening=0, weight_decay=0, nesterov=False)\n",
        "train(net, 100, \"Exp1-training-loss-beta1=\"+str(beta_1)+\";bs=\"+str(batchsize), \"Exp1-test-accuracy-beta1=\"+str(beta_1)+\";bs=\"+str(batchsize), \"Exp1-train-accuracy-beta1=\"+str(beta_1)+\";bs=\"+str(batchsize), 0.001, batchsize, device)\n",
        "print('Finished Training')\n",
        "PATH = './cifar_net.pth'\n",
        "torch.save(net.state_dict(), PATH)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "name": "cifar_new_resnet_original.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gpu_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
